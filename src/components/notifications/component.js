import React, { useState, useEffect } from 'react';
import Notification from 'components/common/notification';
import { useRecoilState } from 'recoil';
import { UUID_State } from 'store';
import { DONE } from 'utils/constants';

const Notifications = () => {
	const [toDisplay, setToDisplay] = useState({});
	const [UUID, setUUID] = useRecoilState(UUID_State);

	const close = (ds) => {
		const rest = Object.keys(toDisplay).reduce((acc, k) => {
			if (k !== ds) {
				acc[k] = toDisplay[k];
			}
			return acc;
		}, {});
		setToDisplay(rest);
	};

	useEffect(() => {
		if (UUID) {
			setTimeout(() => {
				Promise.resolve({
					id: '0356ac58-dd64-44ac-ba31-d8fde40cd468',
					status: 'RUNNING',
					outputs: {
						ds1: { location: 'there', status: 'RUNNING' },
						ds2: { location: 'there', status: 'DONE' },
						ds3: { location: 'there', status: 'FAILED' },
						ds4: { location: 'there', status: 'READY' },
					},
				}).then(({ status, outputs }) => {
					if (status === DONE) {
						setUUID(null);
					}
					const toAdd = Object.entries(outputs).reduce(
						(acc, [name, values]) => ({
							...acc,
							[name]: values,
						}),
						{}
					);
					setToDisplay({ ...toDisplay, ...toAdd });
				});
				setTimeout(() => {
					Promise.resolve({
						id: '0356ac58-dd64-44ac-ba31-d8fde40cd468',
						status: 'DONE',
						outputs: {
							ds1: { location: 'there', status: 'DONE' },
							ds2: { location: 'there', status: 'DONE' },
							ds3: { location: 'there', status: 'DONE' },
							ds4: { location: 'there', status: 'DONE' },
						},
					}).then(({ status, outputs }) => {
						if (status === DONE) {
							setUUID(null);
						}
						const toAdd = Object.entries(outputs).reduce(
							(acc, [name, values]) => ({
								...acc,
								[name]: values,
							}),
							{}
						);
						setToDisplay({ ...toDisplay, ...toAdd });
					});
				}, 3000);
			}, 3000);
		}
	}, [UUID]);
	console.log(toDisplay);
	return (
		<>
			{Object.entries(toDisplay).map(([name, { location, status }], i) => (
				<Notification
					key={i}
					index={i}
					name={name}
					location={location}
					status={status}
					close={close}
				/>
			))}
		</>
	);
};

const job = {
	id: '0356ac58-dd64-44ac-ba31-d8fde40cd468',
	definition: {
		vtlScript: 'ds_strate1 := crabe[filter lgt_social = true and nb_pers > 1];',
		bindings: {
			crabe: 'src/main/resources/crabe',
		},
		toSave: {
			ds_strate1: '/foo/bar',
		},
	},
	status: 'FAILED',
	outputs: {},
	error: {
		cause: {
			cause: {
				cause: null,
				stackTrace: [
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: 'app',
						methodName: 'create',
						fileName: 'ChecksumFileSystem.java',
						lineNumber: 460,
						className: 'org.apache.hadoop.fs.ChecksumFileSystem',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: 'app',
						methodName: 'create',
						fileName: 'ChecksumFileSystem.java',
						lineNumber: 445,
						className: 'org.apache.hadoop.fs.ChecksumFileSystem',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: 'app',
						methodName: 'create',
						fileName: 'FileSystem.java',
						lineNumber: 1125,
						className: 'org.apache.hadoop.fs.FileSystem',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: 'app',
						methodName: 'create',
						fileName: 'FileSystem.java',
						lineNumber: 1105,
						className: 'org.apache.hadoop.fs.FileSystem',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: 'app',
						methodName: 'create',
						fileName: 'HadoopOutputFile.java',
						lineNumber: 74,
						className: 'org.apache.parquet.hadoop.util.HadoopOutputFile',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: 'app',
						methodName: '<init>',
						fileName: 'ParquetFileWriter.java',
						lineNumber: 248,
						className: 'org.apache.parquet.hadoop.ParquetFileWriter',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: 'app',
						methodName: 'getRecordWriter',
						fileName: 'ParquetOutputFormat.java',
						lineNumber: 390,
						className: 'org.apache.parquet.hadoop.ParquetOutputFormat',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: 'app',
						methodName: 'getRecordWriter',
						fileName: 'ParquetOutputFormat.java',
						lineNumber: 349,
						className: 'org.apache.parquet.hadoop.ParquetOutputFormat',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: 'app',
						methodName: '<init>',
						fileName: 'ParquetOutputWriter.scala',
						lineNumber: 36,
						className:
							'org.apache.spark.sql.execution.datasources.parquet.ParquetOutputWriter',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: 'app',
						methodName: 'newInstance',
						fileName: 'ParquetFileFormat.scala',
						lineNumber: 149,
						className:
							'org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anon$1',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: 'app',
						methodName: 'newOutputWriter',
						fileName: 'FileFormatDataWriter.scala',
						lineNumber: 126,
						className:
							'org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: 'app',
						methodName: '<init>',
						fileName: 'FileFormatDataWriter.scala',
						lineNumber: 111,
						className:
							'org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: 'app',
						methodName: 'executeTask',
						fileName: 'FileFormatWriter.scala',
						lineNumber: 269,
						className:
							'org.apache.spark.sql.execution.datasources.FileFormatWriter$',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: 'app',
						methodName: '$anonfun$write$15',
						fileName: 'FileFormatWriter.scala',
						lineNumber: 210,
						className:
							'org.apache.spark.sql.execution.datasources.FileFormatWriter$',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: null,
						methodName: 'apply',
						fileName: null,
						lineNumber: -1,
						className:
							'org.apache.spark.sql.execution.datasources.FileFormatWriter$$$Lambda$3122/00000000E42875A0',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: 'app',
						methodName: 'runTask',
						fileName: 'ResultTask.scala',
						lineNumber: 90,
						className: 'org.apache.spark.scheduler.ResultTask',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: 'app',
						methodName: 'run',
						fileName: 'Task.scala',
						lineNumber: 131,
						className: 'org.apache.spark.scheduler.Task',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: 'app',
						methodName: '$anonfun$run$3',
						fileName: 'Executor.scala',
						lineNumber: 497,
						className: 'org.apache.spark.executor.Executor$TaskRunner',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: null,
						methodName: 'apply',
						fileName: null,
						lineNumber: -1,
						className:
							'org.apache.spark.executor.Executor$TaskRunner$$Lambda$2079/00000000E40153B0',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: 'app',
						methodName: 'tryWithSafeFinally',
						fileName: 'Utils.scala',
						lineNumber: 1439,
						className: 'org.apache.spark.util.Utils$',
						nativeMethod: false,
					},
					{
						moduleName: null,
						moduleVersion: null,
						classLoaderName: 'app',
						methodName: 'run',
						fileName: 'Executor.scala',
						lineNumber: 500,
						className: 'org.apache.spark.executor.Executor$TaskRunner',
						nativeMethod: false,
					},
					{
						moduleName: 'java.base',
						moduleVersion: '14.0.2',
						classLoaderName: null,
						methodName: 'runWorker',
						fileName: 'ThreadPoolExecutor.java',
						lineNumber: 1130,
						className: 'java.util.concurrent.ThreadPoolExecutor',
						nativeMethod: false,
					},
					{
						moduleName: 'java.base',
						moduleVersion: '14.0.2',
						classLoaderName: null,
						methodName: 'run',
						fileName: 'ThreadPoolExecutor.java',
						lineNumber: 630,
						className: 'java.util.concurrent.ThreadPoolExecutor$Worker',
						nativeMethod: false,
					},
					{
						moduleName: 'java.base',
						moduleVersion: '14.0.2',
						classLoaderName: null,
						methodName: 'run',
						fileName: 'Thread.java',
						lineNumber: 851,
						className: 'java.lang.Thread',
						nativeMethod: false,
					},
				],
				message:
					'Mkdirs failed to create file:/foo/bar/parquet/_temporary/0/_temporary/attempt_202106071549407514076948030553871_0003_m_000000_3 (exists=false, cwd=file:/home/hadrien/Projects/SSB/INSEE/VTL-Lab)',
				localizedMessage:
					'Mkdirs failed to create file:/foo/bar/parquet/_temporary/0/_temporary/attempt_202106071549407514076948030553871_0003_m_000000_3 (exists=false, cwd=file:/home/hadrien/Projects/SSB/INSEE/VTL-Lab)',
				suppressed: [],
			},
			stackTrace: [
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'failJobAndIndependentStages',
					fileName: 'DAGScheduler.scala',
					lineNumber: 2258,
					className: 'org.apache.spark.scheduler.DAGScheduler',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: '$anonfun$abortStage$2',
					fileName: 'DAGScheduler.scala',
					lineNumber: 2207,
					className: 'org.apache.spark.scheduler.DAGScheduler',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: '$anonfun$abortStage$2$adapted',
					fileName: 'DAGScheduler.scala',
					lineNumber: 2206,
					className: 'org.apache.spark.scheduler.DAGScheduler',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: null,
					methodName: 'apply',
					fileName: null,
					lineNumber: -1,
					className:
						'org.apache.spark.scheduler.DAGScheduler$$Lambda$3158/00000000B01691B0',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'foreach',
					fileName: 'ResizableArray.scala',
					lineNumber: 62,
					className: 'scala.collection.mutable.ResizableArray',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'foreach$',
					fileName: 'ResizableArray.scala',
					lineNumber: 55,
					className: 'scala.collection.mutable.ResizableArray',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'foreach',
					fileName: 'ArrayBuffer.scala',
					lineNumber: 49,
					className: 'scala.collection.mutable.ArrayBuffer',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'abortStage',
					fileName: 'DAGScheduler.scala',
					lineNumber: 2206,
					className: 'org.apache.spark.scheduler.DAGScheduler',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: '$anonfun$handleTaskSetFailed$1',
					fileName: 'DAGScheduler.scala',
					lineNumber: 1079,
					className: 'org.apache.spark.scheduler.DAGScheduler',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: '$anonfun$handleTaskSetFailed$1$adapted',
					fileName: 'DAGScheduler.scala',
					lineNumber: 1079,
					className: 'org.apache.spark.scheduler.DAGScheduler',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: null,
					methodName: 'apply',
					fileName: null,
					lineNumber: -1,
					className:
						'org.apache.spark.scheduler.DAGScheduler$$Lambda$3156/00000000B0168220',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'foreach',
					fileName: 'Option.scala',
					lineNumber: 407,
					className: 'scala.Option',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'handleTaskSetFailed',
					fileName: 'DAGScheduler.scala',
					lineNumber: 1079,
					className: 'org.apache.spark.scheduler.DAGScheduler',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'doOnReceive',
					fileName: 'DAGScheduler.scala',
					lineNumber: 2445,
					className: 'org.apache.spark.scheduler.DAGSchedulerEventProcessLoop',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'onReceive',
					fileName: 'DAGScheduler.scala',
					lineNumber: 2387,
					className: 'org.apache.spark.scheduler.DAGSchedulerEventProcessLoop',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'onReceive',
					fileName: 'DAGScheduler.scala',
					lineNumber: 2376,
					className: 'org.apache.spark.scheduler.DAGSchedulerEventProcessLoop',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'run',
					fileName: 'EventLoop.scala',
					lineNumber: 49,
					className: 'org.apache.spark.util.EventLoop$$anon$1',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'runJob',
					fileName: 'DAGScheduler.scala',
					lineNumber: 868,
					className: 'org.apache.spark.scheduler.DAGScheduler',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'runJob',
					fileName: 'SparkContext.scala',
					lineNumber: 2196,
					className: 'org.apache.spark.SparkContext',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'write',
					fileName: 'FileFormatWriter.scala',
					lineNumber: 200,
					className:
						'org.apache.spark.sql.execution.datasources.FileFormatWriter$',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'run',
					fileName: 'InsertIntoHadoopFsRelationCommand.scala',
					lineNumber: 188,
					className:
						'org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'sideEffectResult$lzycompute',
					fileName: 'commands.scala',
					lineNumber: 108,
					className:
						'org.apache.spark.sql.execution.command.DataWritingCommandExec',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'sideEffectResult',
					fileName: 'commands.scala',
					lineNumber: 106,
					className:
						'org.apache.spark.sql.execution.command.DataWritingCommandExec',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'doExecute',
					fileName: 'commands.scala',
					lineNumber: 131,
					className:
						'org.apache.spark.sql.execution.command.DataWritingCommandExec',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: '$anonfun$execute$1',
					fileName: 'SparkPlan.scala',
					lineNumber: 180,
					className: 'org.apache.spark.sql.execution.SparkPlan',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: null,
					methodName: 'apply',
					fileName: null,
					lineNumber: -1,
					className:
						'org.apache.spark.sql.execution.SparkPlan$$Lambda$2800/000000002E5DB910',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: '$anonfun$executeQuery$1',
					fileName: 'SparkPlan.scala',
					lineNumber: 218,
					className: 'org.apache.spark.sql.execution.SparkPlan',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: null,
					methodName: 'apply',
					fileName: null,
					lineNumber: -1,
					className:
						'org.apache.spark.sql.execution.SparkPlan$$Lambda$2801/000000002E5DBEC0',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'withScope',
					fileName: 'RDDOperationScope.scala',
					lineNumber: 151,
					className: 'org.apache.spark.rdd.RDDOperationScope$',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'executeQuery',
					fileName: 'SparkPlan.scala',
					lineNumber: 215,
					className: 'org.apache.spark.sql.execution.SparkPlan',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'execute',
					fileName: 'SparkPlan.scala',
					lineNumber: 176,
					className: 'org.apache.spark.sql.execution.SparkPlan',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'toRdd$lzycompute',
					fileName: 'QueryExecution.scala',
					lineNumber: 132,
					className: 'org.apache.spark.sql.execution.QueryExecution',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'toRdd',
					fileName: 'QueryExecution.scala',
					lineNumber: 131,
					className: 'org.apache.spark.sql.execution.QueryExecution',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: '$anonfun$runCommand$1',
					fileName: 'DataFrameWriter.scala',
					lineNumber: 989,
					className: 'org.apache.spark.sql.DataFrameWriter',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: null,
					methodName: 'apply',
					fileName: null,
					lineNumber: -1,
					className:
						'org.apache.spark.sql.DataFrameWriter$$Lambda$3086/000000002E8B1050',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: '$anonfun$withNewExecutionId$5',
					fileName: 'SQLExecution.scala',
					lineNumber: 103,
					className: 'org.apache.spark.sql.execution.SQLExecution$',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: null,
					methodName: 'apply',
					fileName: null,
					lineNumber: -1,
					className:
						'org.apache.spark.sql.execution.SQLExecution$$$Lambda$2625/000000002E26EDA0',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'withSQLConfPropagated',
					fileName: 'SQLExecution.scala',
					lineNumber: 163,
					className: 'org.apache.spark.sql.execution.SQLExecution$',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: '$anonfun$withNewExecutionId$1',
					fileName: 'SQLExecution.scala',
					lineNumber: 90,
					className: 'org.apache.spark.sql.execution.SQLExecution$',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: null,
					methodName: 'apply',
					fileName: null,
					lineNumber: -1,
					className:
						'org.apache.spark.sql.execution.SQLExecution$$$Lambda$2621/000000002CC72BF0',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'withActive',
					fileName: 'SparkSession.scala',
					lineNumber: 775,
					className: 'org.apache.spark.sql.SparkSession',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'withNewExecutionId',
					fileName: 'SQLExecution.scala',
					lineNumber: 64,
					className: 'org.apache.spark.sql.execution.SQLExecution$',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'runCommand',
					fileName: 'DataFrameWriter.scala',
					lineNumber: 989,
					className: 'org.apache.spark.sql.DataFrameWriter',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'saveToV1Source',
					fileName: 'DataFrameWriter.scala',
					lineNumber: 438,
					className: 'org.apache.spark.sql.DataFrameWriter',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'saveInternal',
					fileName: 'DataFrameWriter.scala',
					lineNumber: 415,
					className: 'org.apache.spark.sql.DataFrameWriter',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'save',
					fileName: 'DataFrameWriter.scala',
					lineNumber: 293,
					className: 'org.apache.spark.sql.DataFrameWriter',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: 'app',
					methodName: 'parquet',
					fileName: 'DataFrameWriter.scala',
					lineNumber: 874,
					className: 'org.apache.spark.sql.DataFrameWriter',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: null,
					methodName: 'lambda$writeSparkDataset$2',
					fileName: 'Utils.java',
					lineNumber: 89,
					className: 'fr.insee.vtl.lab.utils.Utils',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: null,
					methodName: 'accept',
					fileName: null,
					lineNumber: -1,
					className:
						'fr.insee.vtl.lab.utils.Utils$$Lambda$3073/000000002E8AA580',
					nativeMethod: false,
				},
				{
					moduleName: 'java.base',
					moduleVersion: '14.0.2',
					classLoaderName: null,
					methodName: 'forEach',
					fileName: 'Map.java',
					lineNumber: 661,
					className: 'java.util.Map',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: null,
					methodName: 'writeSparkDataset',
					fileName: 'Utils.java',
					lineNumber: 86,
					className: 'fr.insee.vtl.lab.utils.Utils',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: null,
					methodName: 'executeLocalSpark',
					fileName: 'SparkEngine.java',
					lineNumber: 84,
					className: 'fr.insee.vtl.lab.service.SparkEngine',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: null,
					methodName: 'lambda$executeNew$0',
					fileName: 'VtlLabController.java',
					lineNumber: 76,
					className: 'fr.insee.vtl.lab.controller.VtlLabController',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: null,
					methodName: 'execute',
					fileName: null,
					lineNumber: -1,
					className:
						'fr.insee.vtl.lab.controller.VtlLabController$$Lambda$798/00000000FC0CD130',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: null,
					methodName: 'lambda$executeJob$1',
					fileName: 'VtlLabController.java',
					lineNumber: 104,
					className: 'fr.insee.vtl.lab.controller.VtlLabController',
					nativeMethod: false,
				},
				{
					moduleName: null,
					moduleVersion: null,
					classLoaderName: null,
					methodName: 'run',
					fileName: null,
					lineNumber: -1,
					className:
						'fr.insee.vtl.lab.controller.VtlLabController$$Lambda$799/00000000FC10E250',
					nativeMethod: false,
				},
				{
					moduleName: 'java.base',
					moduleVersion: '14.0.2',
					classLoaderName: null,
					methodName: 'call',
					fileName: 'Executors.java',
					lineNumber: 515,
					className: 'java.util.concurrent.Executors$RunnableAdapter',
					nativeMethod: false,
				},
				{
					moduleName: 'java.base',
					moduleVersion: '14.0.2',
					classLoaderName: null,
					methodName: 'run$$$capture',
					fileName: 'FutureTask.java',
					lineNumber: 264,
					className: 'java.util.concurrent.FutureTask',
					nativeMethod: false,
				},
				{
					moduleName: 'java.base',
					moduleVersion: '14.0.2',
					classLoaderName: null,
					methodName: 'run',
					fileName: 'FutureTask.java',
					lineNumber: -1,
					className: 'java.util.concurrent.FutureTask',
					nativeMethod: false,
				},
				{
					moduleName: 'java.base',
					moduleVersion: '14.0.2',
					classLoaderName: null,
					methodName: 'runWorker',
					fileName: 'ThreadPoolExecutor.java',
					lineNumber: 1130,
					className: 'java.util.concurrent.ThreadPoolExecutor',
					nativeMethod: false,
				},
				{
					moduleName: 'java.base',
					moduleVersion: '14.0.2',
					classLoaderName: null,
					methodName: 'run',
					fileName: 'ThreadPoolExecutor.java',
					lineNumber: 630,
					className: 'java.util.concurrent.ThreadPoolExecutor$Worker',
					nativeMethod: false,
				},
				{
					moduleName: 'java.base',
					moduleVersion: '14.0.2',
					classLoaderName: null,
					methodName: 'run',
					fileName: 'Thread.java',
					lineNumber: 851,
					className: 'java.lang.Thread',
					nativeMethod: false,
				},
			],
			message:
				'Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3) (192.168.86.23 executor driver): java.io.IOException: Mkdirs failed to create file:/foo/bar/parquet/_temporary/0/_temporary/attempt_202106071549407514076948030553871_0003_m_000000_3 (exists=false, cwd=file:/home/hadrien/Projects/SSB/INSEE/VTL-Lab)\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:460)\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:445)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1125)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1105)\n\tat org.apache.parquet.hadoop.util.HadoopOutputFile.create(HadoopOutputFile.java:74)\n\tat org.apache.parquet.hadoop.ParquetFileWriter.<init>(ParquetFileWriter.java:248)\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:390)\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:349)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetOutputWriter.<init>(ParquetOutputWriter.scala:36)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anon$1.newInstance(ParquetFileFormat.scala:149)\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$$Lambda$3122/00000000E42875A0.apply(Unknown Source)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2079/00000000E40153B0.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)\n\tat java.base/java.lang.Thread.run(Thread.java:851)\n\nDriver stacktrace:',
			localizedMessage:
				'Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 3) (192.168.86.23 executor driver): java.io.IOException: Mkdirs failed to create file:/foo/bar/parquet/_temporary/0/_temporary/attempt_202106071549407514076948030553871_0003_m_000000_3 (exists=false, cwd=file:/home/hadrien/Projects/SSB/INSEE/VTL-Lab)\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:460)\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:445)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1125)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1105)\n\tat org.apache.parquet.hadoop.util.HadoopOutputFile.create(HadoopOutputFile.java:74)\n\tat org.apache.parquet.hadoop.ParquetFileWriter.<init>(ParquetFileWriter.java:248)\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:390)\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:349)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetOutputWriter.<init>(ParquetOutputWriter.scala:36)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anon$1.newInstance(ParquetFileFormat.scala:149)\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)\n\tat org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$$Lambda$3122/00000000E42875A0.apply(Unknown Source)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2079/00000000E40153B0.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)\n\tat java.base/java.lang.Thread.run(Thread.java:851)\n\nDriver stacktrace:',
			suppressed: [],
		},
		stackTrace: [
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: 'write',
				fileName: 'FileFormatWriter.scala',
				lineNumber: 231,
				className:
					'org.apache.spark.sql.execution.datasources.FileFormatWriter$',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: 'run',
				fileName: 'InsertIntoHadoopFsRelationCommand.scala',
				lineNumber: 188,
				className:
					'org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: 'sideEffectResult$lzycompute',
				fileName: 'commands.scala',
				lineNumber: 108,
				className:
					'org.apache.spark.sql.execution.command.DataWritingCommandExec',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: 'sideEffectResult',
				fileName: 'commands.scala',
				lineNumber: 106,
				className:
					'org.apache.spark.sql.execution.command.DataWritingCommandExec',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: 'doExecute',
				fileName: 'commands.scala',
				lineNumber: 131,
				className:
					'org.apache.spark.sql.execution.command.DataWritingCommandExec',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: '$anonfun$execute$1',
				fileName: 'SparkPlan.scala',
				lineNumber: 180,
				className: 'org.apache.spark.sql.execution.SparkPlan',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: null,
				methodName: 'apply',
				fileName: null,
				lineNumber: -1,
				className:
					'org.apache.spark.sql.execution.SparkPlan$$Lambda$2800/000000002E5DB910',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: '$anonfun$executeQuery$1',
				fileName: 'SparkPlan.scala',
				lineNumber: 218,
				className: 'org.apache.spark.sql.execution.SparkPlan',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: null,
				methodName: 'apply',
				fileName: null,
				lineNumber: -1,
				className:
					'org.apache.spark.sql.execution.SparkPlan$$Lambda$2801/000000002E5DBEC0',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: 'withScope',
				fileName: 'RDDOperationScope.scala',
				lineNumber: 151,
				className: 'org.apache.spark.rdd.RDDOperationScope$',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: 'executeQuery',
				fileName: 'SparkPlan.scala',
				lineNumber: 215,
				className: 'org.apache.spark.sql.execution.SparkPlan',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: 'execute',
				fileName: 'SparkPlan.scala',
				lineNumber: 176,
				className: 'org.apache.spark.sql.execution.SparkPlan',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: 'toRdd$lzycompute',
				fileName: 'QueryExecution.scala',
				lineNumber: 132,
				className: 'org.apache.spark.sql.execution.QueryExecution',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: 'toRdd',
				fileName: 'QueryExecution.scala',
				lineNumber: 131,
				className: 'org.apache.spark.sql.execution.QueryExecution',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: '$anonfun$runCommand$1',
				fileName: 'DataFrameWriter.scala',
				lineNumber: 989,
				className: 'org.apache.spark.sql.DataFrameWriter',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: null,
				methodName: 'apply',
				fileName: null,
				lineNumber: -1,
				className:
					'org.apache.spark.sql.DataFrameWriter$$Lambda$3086/000000002E8B1050',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: '$anonfun$withNewExecutionId$5',
				fileName: 'SQLExecution.scala',
				lineNumber: 103,
				className: 'org.apache.spark.sql.execution.SQLExecution$',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: null,
				methodName: 'apply',
				fileName: null,
				lineNumber: -1,
				className:
					'org.apache.spark.sql.execution.SQLExecution$$$Lambda$2625/000000002E26EDA0',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: 'withSQLConfPropagated',
				fileName: 'SQLExecution.scala',
				lineNumber: 163,
				className: 'org.apache.spark.sql.execution.SQLExecution$',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: '$anonfun$withNewExecutionId$1',
				fileName: 'SQLExecution.scala',
				lineNumber: 90,
				className: 'org.apache.spark.sql.execution.SQLExecution$',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: null,
				methodName: 'apply',
				fileName: null,
				lineNumber: -1,
				className:
					'org.apache.spark.sql.execution.SQLExecution$$$Lambda$2621/000000002CC72BF0',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: 'withActive',
				fileName: 'SparkSession.scala',
				lineNumber: 775,
				className: 'org.apache.spark.sql.SparkSession',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: 'withNewExecutionId',
				fileName: 'SQLExecution.scala',
				lineNumber: 64,
				className: 'org.apache.spark.sql.execution.SQLExecution$',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: 'runCommand',
				fileName: 'DataFrameWriter.scala',
				lineNumber: 989,
				className: 'org.apache.spark.sql.DataFrameWriter',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: 'saveToV1Source',
				fileName: 'DataFrameWriter.scala',
				lineNumber: 438,
				className: 'org.apache.spark.sql.DataFrameWriter',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: 'saveInternal',
				fileName: 'DataFrameWriter.scala',
				lineNumber: 415,
				className: 'org.apache.spark.sql.DataFrameWriter',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: 'save',
				fileName: 'DataFrameWriter.scala',
				lineNumber: 293,
				className: 'org.apache.spark.sql.DataFrameWriter',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: 'app',
				methodName: 'parquet',
				fileName: 'DataFrameWriter.scala',
				lineNumber: 874,
				className: 'org.apache.spark.sql.DataFrameWriter',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: null,
				methodName: 'lambda$writeSparkDataset$2',
				fileName: 'Utils.java',
				lineNumber: 89,
				className: 'fr.insee.vtl.lab.utils.Utils',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: null,
				methodName: 'accept',
				fileName: null,
				lineNumber: -1,
				className: 'fr.insee.vtl.lab.utils.Utils$$Lambda$3073/000000002E8AA580',
				nativeMethod: false,
			},
			{
				moduleName: 'java.base',
				moduleVersion: '14.0.2',
				classLoaderName: null,
				methodName: 'forEach',
				fileName: 'Map.java',
				lineNumber: 661,
				className: 'java.util.Map',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: null,
				methodName: 'writeSparkDataset',
				fileName: 'Utils.java',
				lineNumber: 86,
				className: 'fr.insee.vtl.lab.utils.Utils',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: null,
				methodName: 'executeLocalSpark',
				fileName: 'SparkEngine.java',
				lineNumber: 84,
				className: 'fr.insee.vtl.lab.service.SparkEngine',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: null,
				methodName: 'lambda$executeNew$0',
				fileName: 'VtlLabController.java',
				lineNumber: 76,
				className: 'fr.insee.vtl.lab.controller.VtlLabController',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: null,
				methodName: 'execute',
				fileName: null,
				lineNumber: -1,
				className:
					'fr.insee.vtl.lab.controller.VtlLabController$$Lambda$798/00000000FC0CD130',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: null,
				methodName: 'lambda$executeJob$1',
				fileName: 'VtlLabController.java',
				lineNumber: 104,
				className: 'fr.insee.vtl.lab.controller.VtlLabController',
				nativeMethod: false,
			},
			{
				moduleName: null,
				moduleVersion: null,
				classLoaderName: null,
				methodName: 'run',
				fileName: null,
				lineNumber: -1,
				className:
					'fr.insee.vtl.lab.controller.VtlLabController$$Lambda$799/00000000FC10E250',
				nativeMethod: false,
			},
			{
				moduleName: 'java.base',
				moduleVersion: '14.0.2',
				classLoaderName: null,
				methodName: 'call',
				fileName: 'Executors.java',
				lineNumber: 515,
				className: 'java.util.concurrent.Executors$RunnableAdapter',
				nativeMethod: false,
			},
			{
				moduleName: 'java.base',
				moduleVersion: '14.0.2',
				classLoaderName: null,
				methodName: 'run$$$capture',
				fileName: 'FutureTask.java',
				lineNumber: 264,
				className: 'java.util.concurrent.FutureTask',
				nativeMethod: false,
			},
			{
				moduleName: 'java.base',
				moduleVersion: '14.0.2',
				classLoaderName: null,
				methodName: 'run',
				fileName: 'FutureTask.java',
				lineNumber: -1,
				className: 'java.util.concurrent.FutureTask',
				nativeMethod: false,
			},
			{
				moduleName: 'java.base',
				moduleVersion: '14.0.2',
				classLoaderName: null,
				methodName: 'runWorker',
				fileName: 'ThreadPoolExecutor.java',
				lineNumber: 1130,
				className: 'java.util.concurrent.ThreadPoolExecutor',
				nativeMethod: false,
			},
			{
				moduleName: 'java.base',
				moduleVersion: '14.0.2',
				classLoaderName: null,
				methodName: 'run',
				fileName: 'ThreadPoolExecutor.java',
				lineNumber: 630,
				className: 'java.util.concurrent.ThreadPoolExecutor$Worker',
				nativeMethod: false,
			},
			{
				moduleName: 'java.base',
				moduleVersion: '14.0.2',
				classLoaderName: null,
				methodName: 'run',
				fileName: 'Thread.java',
				lineNumber: 851,
				className: 'java.lang.Thread',
				nativeMethod: false,
			},
		],
		message: 'Job aborted.',
		localizedMessage: 'Job aborted.',
		suppressed: [],
	},
};

export default Notifications;
